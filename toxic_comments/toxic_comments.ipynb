{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Импорт-библиотек\" data-toc-modified-id=\"Импорт-библиотек-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Импорт библиотек</a></span></li><li><span><a href=\"#Объявление-функций\" data-toc-modified-id=\"Объявление-функций-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Объявление функций</a></span></li><li><span><a href=\"#Чтение-и-анализ-данных\" data-toc-modified-id=\"Чтение-и-анализ-данных-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Чтение и анализ данных</a></span></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Логистическая регрессия</a></span></li><li><span><a href=\"#Дерево-решений\" data-toc-modified-id=\"Дерево-решений-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Дерево решений</a></span></li><li><span><a href=\"#Тестирование-лучшей-модели\" data-toc-modified-id=\"Тестирование-лучшей-модели-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Тестирование лучшей модели</a></span></li></ul></li><li><span><a href=\"#BERT\" data-toc-modified-id=\"BERT-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>BERT</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Выводы</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификация комментариев по тональности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Необходимо обучить модель классифицировать комментарии на позитивные и негативные.  \n",
    "\n",
    "В нашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Требуется построить модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`.  \n",
    "\n",
    "Столбец *text* содержит текст комментария,  \n",
    "*toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импорт библиотек\n",
    "Произведем импорт всех необходимых бибилиотек:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# библиотеки работы с данными\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# откючаем предупреждения\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# разделение на выборки\n",
    "from sklearn.model_selection import train_test_split  \n",
    "\n",
    "# модели\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# метрики\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# тексты\n",
    "import nltk # инструментарий естественного языка\n",
    "import re # работа с регулярными выражениями\n",
    "import string # содержит набор полезных констант (напр, punctuation)\n",
    "from nltk.stem.wordnet import WordNetLemmatizer # лемматизация\n",
    "from nltk import word_tokenize, sent_tokenize, pos_tag # токенизация\n",
    "from nltk.corpus import stopwords as nltk_stopwords # стоп-слова\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # счётчик величин TF-IDF\n",
    "\n",
    "from itertools import product # аналог вложенных циклов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Объявление функций\n",
    "\n",
    "**Запишем все функции, которые понадобятся нам в проекте:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод общей информации о датафрейме:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info(df):\n",
    "    print('Строки/столбцы:', df.shape)\n",
    "    print('\\nПропуски:',df.isna().sum().sum())\n",
    "    print('\\nДубликаты:',df.duplicated().sum())\n",
    "    print('\\nИнформация:')\n",
    "    print(df.info())\n",
    "    print('\\nЗначения целевого столбца toxic:')\n",
    "    print(df.toxic.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Деление датасета на 3 выборки: обучающую, валидационную и тестовую:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_valid_split(df, test_size, valid_size):\n",
    "\n",
    "    train, test = train_test_split(df, test_size = test_size, shuffle = False)\n",
    "    post_split_valid_size = valid_size / (1 - test_size)\n",
    "    train, valid = train_test_split(train, test_size = post_split_valid_size, shuffle =False)\n",
    "    \n",
    "    return train, test, valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция лемматизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    \n",
    "    # Определение токенов\n",
    "    tokens = [ word for sent in sent_tokenize(text) for word in word_tokenize(sent)]\n",
    "    tokens = list(filter(lambda t: t not in punctuation, tokens)) # Удаление знаков препинания внутри слов\n",
    "    tokens = list(filter(lambda t: t.lower() not in stop_words, tokens)) # Удаление стоп-слов\n",
    "    filtered_tokens = []\n",
    "    \n",
    "    # Регулярные выражения\n",
    "    for token in tokens: \n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    filtered_tokens = list(\n",
    "        map(lambda token: wordnet_lemmatizer.lemmatize(token.lower()), filtered_tokens)) # Лемматизация токенов\n",
    "    filtered_tokens = list(filter(lambda t: t not in punctuation, filtered_tokens)) # Фильтр знаков препинания\n",
    "    \n",
    "    # При выводе избавимся от лишних пробелов\n",
    "    return ' '.join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чтение и анализ данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитаем датасет из файла csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =  pd.read_csv('/datasets/toxic_comments.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Просмотрим общую информацию о нем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Строки/столбцы: (159571, 2)\n",
      "\n",
      "Пропуски: 0\n",
      "\n",
      "Дубликаты: 0\n",
      "\n",
      "Информация:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n",
      "None\n",
      "\n",
      "Значения целевого столбца toxic:\n",
      "0    143346\n",
      "1     16225\n",
      "Name: toxic, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "info(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что в датасете пропуски и дубликаты отсутствуют, все типы данных и названия столбцов корректны.  \n",
    "В целевом столбце отстуствуют лишние значения, он бинарен (состоит из нулей и единиц), что соответствует логике  \n",
    "Присутствует дисбаланс классов (токсичных комментариев меньше)\n",
    "\n",
    "Посмотрим на процентное сдержание токсичных комментариев:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процентное содержание токсичных комментариев: 10.17%\n"
     ]
    }
   ],
   "source": [
    "toxic_ratio = pd.Series( df['toxic'] == 1 ).sum() / df.shape[0]\n",
    "\n",
    "print( 'Процентное содержание токсичных комментариев: {:.2%}'.format(toxic_ratio) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение стоп слов\n",
    "stop_words = set(nltk_stopwords.words('english'))\n",
    "\n",
    "# Cчётчик с указанными в нём стоп-словами\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stop_words)\n",
    "\n",
    "# Определение словаря знаков препинания \n",
    "punctuation = string.punctuation \n",
    "\n",
    "# Определение функций лемматизатора\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 44s, sys: 540 ms, total: 2min 44s\n",
      "Wall time: 2min 45s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(159571, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df['text_clean'] = df['text'].map(tokenizer)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d'aww match background colour 'm seemingly stu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man 'm really trying edit war 's guy const...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>ca n't make real suggestion improvement wonder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>sir hero chance remember page 's</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                          text_clean  \n",
       "0  explanation edits made username hardcore metal...  \n",
       "1  d'aww match background colour 'm seemingly stu...  \n",
       "2  hey man 'm really trying edit war 's guy const...  \n",
       "3  ca n't make real suggestion improvement wonder...  \n",
       "4                   sir hero chance remember page 's  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим датасет на тренировочный, валидационный и тестовый:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер train: (111698, 3) \n",
      "Размер test: (15958, 3) \n",
      "Размер valid: (31915, 3)\n"
     ]
    }
   ],
   "source": [
    "train, test, valid = train_test_valid_split(df, 0.1, 0.2)\n",
    "\n",
    "print('Размер train:', train.shape,\n",
    "     '\\nРазмер test:', test.shape, \n",
    "     '\\nРазмер valid:', valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "В рамках данного пункта:  \n",
    "* мы провели первичный анализ данных (выяснив, что около 10% от всех комментариев являются токсичными)\n",
    "* создали столбец с лемматизированным и очищенным текстом (для лемматизации и очистки текста от лишних символов и пробелов мы использовали регулярные выражения)\n",
    "* и подготовили выборки (train, test, valid) для обучения моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы алгоритмы умели определять тематику и тональность текста, их нужно обучить на корпусе (с разметкой эмоций и ключевых слов).  \n",
    "Создадим корпус постов: для этого преобразуем столбец 'text_clean' в список текстов и переведем в кодировку Unicode (U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = train['text_clean'].values.astype('U')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы посчитать TF-IDF для корпуса текстов, вызовем функцию fit_transform()  \n",
    "fit() вызовем только на тренировочной выборке, т.к. данные уже поделены"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train = count_tf_idf.fit_transform(train_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия\n",
    "\n",
    "Без подбора параметров (по дефолту penalty = l2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика F1 на  0.7266475644699141\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(tfidf_train, train['toxic'])\n",
    "\n",
    "valid_corpus = valid['text_clean'].values.astype('U')\n",
    "tfidf_valid = count_tf_idf.transform(valid_corpus)\n",
    " \n",
    "pred_valid = model.predict(tfidf_valid)\n",
    "\n",
    "f1_lr = f1_score(valid['toxic'],  pred_valid)\n",
    "\n",
    "print('Метрика F1 на ', f1_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По заданию требуется достичь значения метрики выше 0.75, а у нас получилось 0.73.  \n",
    "Это значение близко к требуемому, но решение не подходит.  \n",
    "Попробуем подобрать параметры логистической регрессии и получить новый результат метрики F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.7 s, sys: 4.76 s, total: 15.4 s\n",
      "Wall time: 15.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\"({'penalty': 'l1'}, {'max_iter': 2})\": 0.7492977528089888,\n",
       " \"({'penalty': 'l1'}, {'max_iter': 5})\": 0.7639639639639639,\n",
       " \"({'penalty': 'l1'}, {'max_iter': 100})\": 0.7647583377920456,\n",
       " \"({'penalty': 'l2'}, {'max_iter': 2})\": 0.0,\n",
       " \"({'penalty': 'l2'}, {'max_iter': 5})\": 0.58335144533797,\n",
       " \"({'penalty': 'l2'}, {'max_iter': 100})\": 0.7266475644699141}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "buf = dict()\n",
    "\n",
    "for i in product([{'penalty':'l1'},{'penalty':'l2'}],\n",
    "              [{'max_iter':2},{ 'max_iter':5}, {'max_iter':100}]\n",
    "              ):\n",
    "    rfr = LogisticRegression(random_state = 123, **i[0],**i[1])\n",
    "    rfr.fit(tfidf_train, train['toxic'])\n",
    "    pred_2 = rfr.predict(tfidf_valid)\n",
    "    buf[str(i)] = f1_score(valid['toxic'], pred_2)\n",
    "    \n",
    "buf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшее значение метрики F1 = 0.76 достигнуто при макс итерации = 5 и штрафе penalty = l1.  \n",
    "Оно подходит по заданию, т.к. больше чем 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дерево решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 26s, sys: 55.7 ms, total: 3min 26s\n",
      "Wall time: 3min 27s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\"({'criterion': 'gini'}, {'max_depth': 5})\": 0.5118805159538357,\n",
       " \"({'criterion': 'gini'}, {'max_depth': 10})\": 0.5924679150010519,\n",
       " \"({'criterion': 'gini'}, {'max_depth': 100})\": 0.7242570836212854,\n",
       " \"({'criterion': 'entropy'}, {'max_depth': 5})\": 0.5124378109452736,\n",
       " \"({'criterion': 'entropy'}, {'max_depth': 10})\": 0.586722866174921,\n",
       " \"({'criterion': 'entropy'}, {'max_depth': 100})\": 0.7010515773660491}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    " \n",
    "buf_1 = dict()\n",
    "\n",
    "for i in product([{'criterion':'gini'}, {'criterion':'entropy'}],\n",
    "              [{'max_depth':5}, { 'max_depth':10}, {'max_depth':100}]\n",
    "              ):\n",
    "    dtc = DecisionTreeClassifier(random_state = 123, **i[0],**i[1])\n",
    "    dtc.fit(tfidf_train, train['toxic'])\n",
    "    pred_3 = dtc.predict(tfidf_valid)\n",
    "    buf_1[str(i)] = f1_score(valid['toxic'],pred_3)\n",
    "    \n",
    "buf_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший показатель F1 при переборе параметров модели дерева решений, оказался ниже чем требуется (0.72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестирование лучшей модели\n",
    "\n",
    "Проверим на тестовой выборке лучшую модель Логистической регрессии, полученную на валидационной выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7605633802816901"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_corpus = test['text_clean'].values.astype('U')\n",
    "tfidf_test = count_tf_idf.transform(test_corpus) \n",
    "\n",
    "best_model = LogisticRegression(random_state = 123 , max_iter = 5, penalty = 'l1')\n",
    "best_model.fit(tfidf_train, train['toxic'])\n",
    "pred_test = best_model.predict(tfidf_test)\n",
    "\n",
    "f1 = f1_score(test['toxic'], pred_test)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Успех. При заданных гиперпараметрах модели логистической регрессии,  \n",
    "на тесте мы получили значение метрики F1 = 0.76, что выше требуемого порога в 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# \n",
    "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')  # Создаем токенизатор\n",
    "tokenized = df['text'][:2500].apply(lambda x: tokenizer.encode(x,truncation=True, add_special_tokens=True)) #Производим токенизацию текстов в датасете\n",
    "\n",
    "max_len = 0  #Находим максимальную длину токенизированного комментария\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "# Создаем матрицу размера max_len x n_tokens (размер максимального токенизированного комментария на кол-во текстов) и маску\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "\n",
    "# Используем заранее обученную BERT-модель\n",
    "model = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Задаем размер батча, т.е. такое кол-во комментариев, которое будет принимать на вход модель\n",
    "batch_size = 100\n",
    "embeddings = []\n",
    "\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "        # проходим по batch_size, типа 0...100, 100....200, и т.д. то есть берем по кусочку матриц\n",
    "        # padded и attention_mask и оборачиваем это в тензоры\n",
    "        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "        # no_grad = без обучения\n",
    "        with torch.no_grad():\n",
    "            # получаем готовый эмбеддинг по батчу и маске\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        # добавляем полученный эмбеддинг в список, переведя его в массив numpy\n",
    "        embeddings.append(batch_embeddings[0][:,0,:].numpy())\n",
    "\n",
    "# Склеиваем полученные знечения в один массив numpy\n",
    "features = np.concatenate(embeddings)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(pd.DataFrame(features), \n",
    "                                                    df['toxic'][:2500],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "print(f1_score(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В рамках данного проекта мы помогли магазину \"Викишоп\" создать инструмент, который будет помогать классифицировать комментарии на позитивные и негативные с целью отправки негативных на дальнейшую модерацию. В поисках лучшего результата, были перебраны гиперпараметры двух моделей: дерево решений и логистическая решрессия. Больше всего нам подошла модель Логистическая регрессия, гиперпараметры которой мы подобрали перебором (max_iter = 5, penalty = 'l1'). В результате метрика качества предсказаний оказалась лучше требуемого порога: F1 = 0.76 против требуемых <= 0.75, поэтому модель принимаем как удачную."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1494,
    "start_time": "2021-07-25T15:39:07.587Z"
   },
   {
    "duration": 784,
    "start_time": "2021-07-25T15:39:34.483Z"
   },
   {
    "duration": 576,
    "start_time": "2021-07-25T15:46:25.520Z"
   },
   {
    "duration": 316,
    "start_time": "2021-07-25T15:46:35.304Z"
   },
   {
    "duration": 322,
    "start_time": "2021-07-25T15:47:49.424Z"
   },
   {
    "duration": 286,
    "start_time": "2021-07-25T15:47:56.327Z"
   },
   {
    "duration": 288,
    "start_time": "2021-07-25T15:48:00.795Z"
   },
   {
    "duration": 302,
    "start_time": "2021-07-25T15:48:39.833Z"
   },
   {
    "duration": 298,
    "start_time": "2021-07-25T15:48:48.496Z"
   },
   {
    "duration": 348,
    "start_time": "2021-07-25T15:49:23.951Z"
   },
   {
    "duration": 324,
    "start_time": "2021-07-25T15:49:35.815Z"
   },
   {
    "duration": 307,
    "start_time": "2021-07-25T15:49:53.719Z"
   },
   {
    "duration": 716,
    "start_time": "2021-07-25T15:50:46.818Z"
   },
   {
    "duration": 741,
    "start_time": "2021-07-25T15:50:54.543Z"
   },
   {
    "duration": 330,
    "start_time": "2021-07-25T15:51:54.183Z"
   },
   {
    "duration": 1510,
    "start_time": "2021-07-26T06:23:05.504Z"
   },
   {
    "duration": 785,
    "start_time": "2021-07-26T06:23:07.017Z"
   },
   {
    "duration": 362,
    "start_time": "2021-07-26T06:23:07.805Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-26T06:30:17.329Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-26T06:30:19.332Z"
   },
   {
    "duration": 7,
    "start_time": "2021-07-26T06:39:22.038Z"
   },
   {
    "duration": 6,
    "start_time": "2021-07-26T06:39:27.052Z"
   },
   {
    "duration": 1551,
    "start_time": "2021-07-26T06:41:25.470Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-26T06:41:27.023Z"
   },
   {
    "duration": 9,
    "start_time": "2021-07-26T06:41:27.031Z"
   },
   {
    "duration": 820,
    "start_time": "2021-07-26T06:41:27.045Z"
   },
   {
    "duration": 565,
    "start_time": "2021-07-26T06:41:27.868Z"
   },
   {
    "duration": 7,
    "start_time": "2021-07-26T06:41:28.436Z"
   },
   {
    "duration": 288,
    "start_time": "2021-07-26T06:42:31.504Z"
   },
   {
    "duration": 8,
    "start_time": "2021-07-26T07:17:26.560Z"
   },
   {
    "duration": 6,
    "start_time": "2021-07-26T07:17:56.072Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-26T07:18:02.024Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-26T07:18:13.080Z"
   },
   {
    "duration": 436,
    "start_time": "2021-07-26T07:19:40.551Z"
   },
   {
    "duration": 279,
    "start_time": "2021-07-26T07:19:48.015Z"
   },
   {
    "duration": 278,
    "start_time": "2021-07-26T07:19:58.821Z"
   },
   {
    "duration": 9,
    "start_time": "2021-07-26T07:20:19.511Z"
   },
   {
    "duration": 248703,
    "start_time": "2021-07-26T07:31:51.306Z"
   },
   {
    "duration": 11,
    "start_time": "2021-07-26T07:36:26.047Z"
   },
   {
    "duration": 606,
    "start_time": "2021-07-26T07:50:45.422Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-26T07:51:27.712Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-26T07:51:43.905Z"
   },
   {
    "duration": 44,
    "start_time": "2021-07-26T07:51:54.985Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-26T07:56:56.319Z"
   },
   {
    "duration": 7,
    "start_time": "2021-07-26T08:05:37.504Z"
   },
   {
    "duration": 8,
    "start_time": "2021-07-26T08:32:49.973Z"
   },
   {
    "duration": 8,
    "start_time": "2021-07-26T08:33:15.054Z"
   },
   {
    "duration": 8,
    "start_time": "2021-07-26T08:33:25.958Z"
   },
   {
    "duration": 7,
    "start_time": "2021-07-26T08:33:42.014Z"
   },
   {
    "duration": 7,
    "start_time": "2021-07-26T08:34:32.078Z"
   },
   {
    "duration": 245,
    "start_time": "2021-07-26T08:40:37.368Z"
   },
   {
    "duration": 6,
    "start_time": "2021-07-26T08:40:50.852Z"
   },
   {
    "duration": 1898,
    "start_time": "2021-07-26T08:55:42.666Z"
   },
   {
    "duration": 8291,
    "start_time": "2021-07-26T08:55:53.516Z"
   },
   {
    "duration": 9274,
    "start_time": "2021-07-26T09:01:06.069Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-26T09:02:06.242Z"
   },
   {
    "duration": 10691,
    "start_time": "2021-07-26T09:15:17.155Z"
   },
   {
    "duration": 8,
    "start_time": "2021-07-26T09:56:12.242Z"
   },
   {
    "duration": 6,
    "start_time": "2021-07-26T10:09:49.338Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-26T10:09:52.723Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-26T10:09:53.004Z"
   },
   {
    "duration": 7,
    "start_time": "2021-07-26T10:09:53.251Z"
   },
   {
    "duration": 773,
    "start_time": "2021-07-26T10:09:53.611Z"
   },
   {
    "duration": 357,
    "start_time": "2021-07-26T10:09:54.387Z"
   },
   {
    "duration": 15,
    "start_time": "2021-07-26T10:09:54.747Z"
   },
   {
    "duration": 41,
    "start_time": "2021-07-26T10:09:54.765Z"
   },
   {
    "duration": 250539,
    "start_time": "2021-07-26T10:09:54.809Z"
   },
   {
    "duration": 12,
    "start_time": "2021-07-26T10:14:05.362Z"
   },
   {
    "duration": 98,
    "start_time": "2021-07-26T10:14:05.377Z"
   },
   {
    "duration": 1588,
    "start_time": "2021-07-26T10:24:37.619Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-26T10:24:39.209Z"
   },
   {
    "duration": 6,
    "start_time": "2021-07-26T10:24:40.171Z"
   },
   {
    "duration": 9,
    "start_time": "2021-07-26T10:24:40.952Z"
   },
   {
    "duration": 798,
    "start_time": "2021-07-26T10:24:42.174Z"
   },
   {
    "duration": 336,
    "start_time": "2021-07-26T10:24:43.190Z"
   },
   {
    "duration": 6,
    "start_time": "2021-07-26T10:24:47.458Z"
   },
   {
    "duration": 8,
    "start_time": "2021-07-26T10:24:47.658Z"
   },
   {
    "duration": 296987,
    "start_time": "2021-07-26T10:24:48.158Z"
   },
   {
    "duration": 23,
    "start_time": "2021-07-26T10:29:45.148Z"
   },
   {
    "duration": 89,
    "start_time": "2021-07-26T10:29:45.174Z"
   },
   {
    "duration": 2155,
    "start_time": "2021-07-26T10:29:45.266Z"
   },
   {
    "duration": 9154,
    "start_time": "2021-07-26T10:29:47.423Z"
   },
   {
    "duration": 11042,
    "start_time": "2021-07-26T10:29:56.581Z"
   },
   {
    "duration": 384,
    "start_time": "2021-07-26T10:30:07.626Z"
   },
   {
    "duration": 705,
    "start_time": "2021-07-26T10:33:30.455Z"
   },
   {
    "duration": 15531,
    "start_time": "2021-07-26T10:34:03.001Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-26T11:09:57.664Z"
   },
   {
    "duration": 15259,
    "start_time": "2021-07-26T11:16:56.469Z"
   },
   {
    "duration": 40,
    "start_time": "2021-07-26T11:17:56.486Z"
   },
   {
    "duration": 323,
    "start_time": "2021-07-26T11:18:18.409Z"
   },
   {
    "duration": 1592,
    "start_time": "2021-07-26T11:18:35.240Z"
   },
   {
    "duration": 6,
    "start_time": "2021-07-26T11:18:36.835Z"
   },
   {
    "duration": 20,
    "start_time": "2021-07-26T11:18:36.845Z"
   },
   {
    "duration": 24,
    "start_time": "2021-07-26T11:18:36.868Z"
   },
   {
    "duration": 828,
    "start_time": "2021-07-26T11:18:36.894Z"
   },
   {
    "duration": 376,
    "start_time": "2021-07-26T11:18:37.725Z"
   },
   {
    "duration": 7,
    "start_time": "2021-07-26T11:18:38.103Z"
   },
   {
    "duration": 11,
    "start_time": "2021-07-26T11:18:38.112Z"
   },
   {
    "duration": 245537,
    "start_time": "2021-07-26T11:18:38.125Z"
   },
   {
    "duration": 12,
    "start_time": "2021-07-26T11:22:43.665Z"
   },
   {
    "duration": 103,
    "start_time": "2021-07-26T11:22:43.680Z"
   },
   {
    "duration": 1978,
    "start_time": "2021-07-26T11:22:43.786Z"
   },
   {
    "duration": 7926,
    "start_time": "2021-07-26T11:22:45.766Z"
   },
   {
    "duration": 10843,
    "start_time": "2021-07-26T11:22:57.020Z"
   },
   {
    "duration": 901,
    "start_time": "2021-07-26T11:23:15.197Z"
   },
   {
    "duration": 15450,
    "start_time": "2021-07-26T11:23:27.790Z"
   },
   {
    "duration": 207529,
    "start_time": "2021-07-26T11:25:10.837Z"
   },
   {
    "duration": 6,
    "start_time": "2021-07-26T11:30:54.481Z"
   },
   {
    "duration": 6047,
    "start_time": "2021-07-26T11:32:56.451Z"
   },
   {
    "duration": 294,
    "start_time": "2021-07-26T11:38:22.739Z"
   },
   {
    "duration": 1625,
    "start_time": "2021-07-26T11:38:35.226Z"
   },
   {
    "duration": 2624,
    "start_time": "2021-07-26T11:39:14.525Z"
   },
   {
    "duration": 2250,
    "start_time": "2021-07-26T11:39:31.393Z"
   },
   {
    "duration": 1248,
    "start_time": "2021-07-26T13:10:19.958Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-26T13:10:27.347Z"
   },
   {
    "duration": 7,
    "start_time": "2021-07-26T13:10:34.990Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-26T13:10:45.551Z"
   },
   {
    "duration": 685,
    "start_time": "2021-07-26T13:11:08.766Z"
   },
   {
    "duration": 278,
    "start_time": "2021-07-26T13:11:10.436Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-26T13:11:21.430Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-26T13:11:39.257Z"
   },
   {
    "duration": 165081,
    "start_time": "2021-07-26T13:11:45.039Z"
   },
   {
    "duration": 8,
    "start_time": "2021-07-26T13:14:30.122Z"
   },
   {
    "duration": 91,
    "start_time": "2021-07-26T13:14:30.132Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
